
= Automatic Employment Decision Technology Analysis with Focus on Bias Against Those with Disabilities

== Abstract

[.indent]
This study examines the potential for screen-out harm to job seekers with disabilities due to inadequate accommodations and accessibility features in automated employment decision tools (AEDTs) based on artificial intelligence or machine learning (AI/ML). Data was collected and analyzed from 30 organizations offering such AEDTs, focusing on publicly available information regarding accommodations and accessibility features, organizational size, specific products offered, bias testing practices, and accessibility staff. Most organizations in the study do not offer accommodations in their AI/ML-enabled AEDT products and are not actively addressing the needs of candidates with disabilities. Worse, some AEDT providers misrepresent their tools with claims of “bias-free” decision making and offer employment assessments based on questionable video analysis approaches. These findings align with broader concerns about the potential for screen-out and other harms as a result of shortcomings in the design and implementation of AEDTs.

* link:https://github.com/midiker/aedt-analysis/blob/main/aedt_analysis.ipynb[Code implementation]

=== Data Dictionary
[cols="1,2,5", options="header"]
|===
|Features|Values|Description


|"Bias-Free"/No bias
|1 = yes, 0 = no,  2=maybe
|If yes, organization’s website displays the term "Bias-Free" or similar language, such as “eliminates bias,” in relation to organization's AI/ML technology or  AI/ML technology in general.

|Video Screening
|1 = yes, 0 = no,  2=maybe
|If yes, organization’s website displays that organization integrates AI/ML screening algorithms in their TA/HR video software.

|Resume/Profile Screening
|1 = yes, 0 = no,  2=maybe
|If yes, organization’s website displays that organization integrates AI/ML screening algorithms on candidates resumes or profiles in their TA/HR software.

|Chatbots
|1 = yes, 0 = no,  2=maybe
|If yes, organization’s website displays that organization integrates Chatbots in their TA/HR software.

|Addresses Physical Disabilities
|1 = yes, 0 = no,  2=maybe
|If yes, organization’s website addresses ways to assist and/or the benefits of hiring candidates with physical disabilities.

|Addresses Neurodiversity
|1 = yes, 0 = no,  2=maybe
|If yes, organization’s website addresses ways to assist and/or the benefits of hiring neurodivergent candidates.

|Public Accessibility Staff
|1 = yes, 0 = no,  2=maybe
|If yes, there is public evidence of accessibility staff on the organization’s website or LinkedIn.

|Offers Accommodations
|1 = yes, 0 = no,  2=maybe
|If yes, organization has accommodations specifically for the AI/ML software

|Immediate/Timeframe for Accommodations
|1 = yes, 0 = no,  2=maybe
|If yes, organization gives immediate accomodations or a timeframe for when accommodations would be to candidates for AI/ML software.

|Reports Bias Testing
|1 = yes, 0 = no,  2=maybe
|If yes, organization states on its website that the organization has a third party audit or its own audits for bias in their AI/ML models. Note: this might not include bias testing for disability.

|Number of Total Staff
|Small < 100, Medium < 1000, Large > 1001
|Estimate total employee count on LinkedIn or other website
|===

== References

[1] “Table A. Employment Status of the Civilian Noninstitutional Population by Disability Status 
and Age, 2020 and 2021 Annual Averages - 2021 A01 Results.” U.S. Bureau of Labor Statistics, 
February 24, 2022. https://www.bls.gov/news.release/disabl.a.htm. 

[2] Whittaker, Meredith, Meryl Alper, Cynthia L. Bennett, Sara Hendren, Liz Kaziunas, Mara 
Mills, Meredith Ringel Morris et al. "Disability, Bias, and AI." AI Now Institute, November, 2019. 
https://ainowinstitute.org/disabilitybiasai-2019.pdf. 

[3] "The Americans with Disabilities Act and the Use of Software, Algorithms, and Artificial 
Intelligence to Assess Job Applicants and Employees." US Equal Employment Opportunity 
Commission, May 12, 2022. https://www.eeoc.gov/laws/guidance/americans-disabilities-act-and-use-software-algorithms-and-artificial-intelligence.

[4] “Managing the Future of Work.” Harvard Business School, December 4, 2022. 
https://www.hbs.edu/managing-the-future-of-work/Pages/default.aspx. 

[5] Schwartz, Reva, Apostol Vassilev, Kristen Greene, Lori Perine, Andrew Burt, and Patrick Hall. 
"Towards a Standard for Identifying and Managing Bias in Artificial Intelligence." NIST Special 
Publication 1270, 2022. https://nvlpubs.nist.gov/nistpubs/SpecialPublications/NIST.SP.1270.pdf. 

[6] “Local Law 144.” The New York City Council, File #: Int 1894-2020. 
https://legistar.council.nyc.gov/LegislationDetail.aspx?ID=4344524&GUID=
B051915D-A9AC-451E-81F8-6596032FA3F9. 

[7] “ISO/IEC JTC 1/SC 42, Artificial Intelligence.” ISO. 2017. 
https://www.iso.org/committee/6794475.html. 

[8] “Autonomous and Intelligent Systems (AIS).” IEEE. 
https://standards.ieee.org/initiatives/autonomous-intelligence-systems/. 

[9] “AI Risk Management Framework.” NIST. January 26, 2023. https://www.nist.gov/itl/ai-risk-management-framework. 

[10] “Building a Future that Works.” PEAT. https://www.peatworks.org/. 

[11] “Welcome to the AI Incident Database.” The Responsible AI Collaborative. 
https://incidentdatabase.ai/.
